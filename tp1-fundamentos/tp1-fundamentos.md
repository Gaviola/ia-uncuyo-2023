1- 
a)
Dentro de la inteligencia artificial nos podemos encontrar con distintas filosofías con respecto al razonamiento de si una máquina es capaz de pensar por si misma y poseer una consciencia o simplemente son capaces de simular el comportamiento humano. Dentro de estas teorías nos podemos encontrar con 2 teorías predominantes, la inteligencia artificial fuerte y la inteligencia artificial débil.

***Inteligencia Artificial Débil***

La inteligencia **artificial débil** es aquella que en la cual se afirma que **las máquinas son capaces de "actuar" de forma humana o racional, aunque realmente no poseen un razonamiento realmente humano**. Para esto se requiere definir de una forma formal que es la inteligencia artificial, labor complicado ya que, de por si, es difícil encontrar una definición rigurosa de que algo sea **"inteligente"**. 
Alan Turing intentó crear una forma de identificar cuando una computadora se puede clasificar como "inteligente" mediante el **Test de Turing**. En dicho test una maquina intenta engañar a una persona intentado replicar una conversación humana.
Turing también argumento que existían tareas que una maquina nunca podría realizar, tales como, tener sentido del humor, enamorarse, diferenciar el bien o el mal, entre otras cosas aunque no por eso se podría clasificar como comportamiento no inteligente.

Una teoría que sustenta la hipótesis se que la inteligencia artificial es inferior a la humana, se ampara en el **teorema de incompletitud** de Godel, por el cual los sistemas formales lo suficientemente poderosos como para realizar operaciones aritméticas (Como lo son las máquina de Turing) no pueden demostrar la veracidad de sus declaraciones dentro del sistema.
Sin embargo algunos investigadores no están de acuerdo en estas afirmaciones y dicen que el hecho de ser incapaz de realizar ciertas cosas no determinan si se puede considerar a la IA inteligente o no y que tampoco es posible probar que el teorema de incompletitud tampoco nos afecta a nosotros como humanos.

Otros investigadores argumentan que el comportamiento humano es demasiado complejo para ser replicado por un simple conjunto de reglas, llamado el **problema de la cualificación**. El problema radica en que una maquina puede basarse en hechos concretos pero no hacer valer las experiencias obtenidas a lo largo del tiempo y aprendiendo de ellas. También una de los argumentos mas fuertes que indican la inferioridad de la IA frente a las personas puede radicar en que su único entendimiento de un objeto se produce unicamente con inferencias lógicas, tales como Perro(X) --> Mamífero(X) y nunca a tenido la experiencia real de ver correr un perro o haber sido lamido por uno.

***Inteligencia Artificial Fuerte***

La inteligencia artificial fuerte es la teoría que, en contraposición con la inteligencia débil, **las máquinas genuinamente pueden ser capaces de pensar, entender y poseer una consciencia como lo haría un ser humano**, es decir, ser conscientes de su estado mental, emociones y sus acciones.
Turing proponía que no tenía mucho sentido preguntarse si **una maquina es capaz de pensar** ya que en la vida cotidiana uno es incapaz de ver los estados mentales de de otros humanos, sin embargo, nadie pone en tela de juicio si una persona es capaz de pensar.

En 1848 se logró sintetizar urea de manera artificial, un hecho que previamente parecía imposible ya que nunca se había logrado sintetizar un material orgánico partiendo de uno inorgánico. Una vez ocurrido el hecho, nadie objeto que el resultado obtenido no sea urea. Con IA esto no ocurre por lo que algunos filósofos creen que la IA no será capaz de ser real.

Turing manifestó que a medida que las maquinas vayan haciéndose mas sofisticadas, la diferencia entre IA débil e IA fuerte se volverían mas indistinguibles. Para esto es necesario primero resolver el **problema de mente-cuerpo**, en el cual los filósofos discuten la conexión que existe entre el cuerpo y la mente. Descartes propuso que el cuerpo y la mente deben existir en diferentes reinos, dando origen a la teoría **dualista**. Por el otro lado encontramos a la **teoría del fisicalismo** que plantea que los estados de la mente son también estados físicos, aunque no se clarifica bien el como.
Uno de los principales argumentos de los fisicalistas son los estados intencionales, tales como saber, creer, desear, etc ya que estos dependen de aspectos del mundo externo. Por lo tanto la descripción del estado mental de una persona depende del estado mental de su cerebro. Esta vision puede llevar a algunas paradojas,ya que si por ejemplo fuera posible extraer el cerebro de una persona y simular toda su vida que hubiera tenido, podrían simularse los estados mentales de hechos reales aunque fueran totalmente falsos, algo similar a lo que plantea la película matrix.

Debido a esta contradicción los estados mentales pueden ser interpretados de 2 maneras. La vista de **contenido amplia** que plantea la vision omnisciente de un observador y la vista de **contenido estrecho** que considera los estados mentales y por lo tanto los estados mentales reales y los simulados son iguales. La vista de contenido amplia describe mejor nuestro lenguaje ordinario, mientras que la vista de contenido estrecha es relevante a la hora de diseñar una IA.

La teoría del **funcionalismo** dice que que los estados mentales es una condición causada por una entrada y una salida. Por lo tanto, 2 sistemas isomorfos podrían tener los mismos estados mentales y por lo tanto una computadora podría tener los mismos estados mentales que una persona. Esta teoría se puede ver plasmada en el **experimento de cambio de cerebro**, en el cual se remplaza lenta y progresivamente todo un cerebro por dispositivos electrónicos. Algunos investigadores afirman que la consciencia se mantendría intacta, mientras que filósofos y biólogos están convencidos de que desaparecería.
Del experimento se pueden extraer 3 conclusiones: 
* Los mecanismos de conciencia reaccionan de la misma manera con el cerebro normal que con los dispositivos electrónicos, por lo tanto son conscientes
* Los eventos mentales no tienen una confección con el comportamiento, es decir, son eventos **epifenomenalistas** y por lo tanto no habría consciencia.
* El experimento es imposible de realizar.
  
John Searle's un **biólogo naturista** plantea que los estados mentales son un resultado de alto nivel de las neuronas, como resultado de sus propiedades. por lo tanto, un estado no podría ser replicado unicamente teniendo la misma estructura funcional. John plantea un sistema hipotético llamado **la habitación china** en el cual una persona, que solo entiende ingles, este encerrada en una habitación (cumpliendo rol de CPU) acompañado de un libro de reglas (programa) y varias pilas de papeles vacíos y con inscripciones. Este recibiría texto en chino y con la ayuda del libro y las pilas de hojas seria capaz de transcribir los símbolos a otros símbolos sin necesidad de saber chino. Como la persona no entiende chino y el libro y las hojas son simples objetos, se podría decir que ejecutar el programa correcto no necesariamente significa generar entendimiento.

John planteó 4 axiomas:
1) Los programas de computadoras son formales (Sintáctico)
2) Las mentes humanas tienen contenidos mentales (Semántica)
3) La sintaxis por si sola no es constitutiva o no es suficiente para la semántica.
4) Los cerebros ocasionan las mentes.
   
Los axiomas 1 y 2 están relacionados con la vision estrecha ya amplia. Siendo generosos interpretando los axiomas, se puede concluir que un programa no es suficiente para tener una mente. Para esto también es necesario negar el funcionalismo (axioma 3), esto se basa en el ejemplo de la habitación china. Searle´s bautizo a la habitación china como una refutación de la IA fuerte.

El gran problema sobre el debate de la IA fuerte es la **conciencia**. Algunos la reducen a el entendimiento de ser consciente de uno mismo. El aspecto en el que nos tenemos que fijar es en la **experiencia subjetiva**. El nombre técnico para la naturaleza intrínseca de la experiencia se llama **qualia**. El mayor desafío de los funcionalistas es como la qualia puede verse involucrada en procesos isomorfos y como la experiencia subjetiva de una persona puede afectar dichos procesos. 

Qualia también es difícil de explicar desde el aspecto científico, ya que si por ejemplo, se conociera por completo el cerebro, no se puede elaborar una conclusion que explique porque esas neuronas tengan una experiencia subjetiva. Dicho vacío explicativo lleva a pensar que los humanos son simplemente incapaces de comprender su propia consciencia.

***La ética y los riesgos de desarrollar inteligencia artificial***

El libro **Ética de la computación** plantea algunos posibles problemas a los cuales nos deberíamos afrontar en las ciencias de la computación.
* La gente puede perder su trabajo frente a la automatización
* La gente tendría mucho tiempo libre (o poco).
* La gente perdería la sensación de ser única.
* La IA puede ser utilizada para fines no deseados.
* El uso de IA puede provocar una perdida de responsabilidad.
* El uso de IA puede significar el fin de la raza humana.

**La gente puede perder su trabajo por la automatización**. Esto ya viene ocurriendo en muchos aspectos de la economía, pero estas han sido enfocadas en prestar una ayuda al humano y no a remplazarlo. En un futuro se podría desarrollar una IA capaz de aprender cualquier trabajo. 

**La gente tendría mucho tiempo libre (o poco)**. Algunos expertos en los 70 predecían que para los 2000, las jornadas laborales se reducirían, hasta incluso un 50% debido a las mejoras tecnológicas. Esto no ha ocurrido del todo como se esperaba ya que las industrias se han vuelto mas intensivas con sistemas computarizados que trabajan 24 horas. Esto beneficia en gran manera aquellos que trabajan mas y mejor, mejorando mucho el margen de ganancias de las industrias.

**La gente perdería la sensación de ser única**. Con el desarrollo del campo de IA, algunos investigadores han llegado a la conclusion de que los humanos puedan ser autómatas. Estas ideas perjudicarían la unicidad de cada persona, aunque no es algo que no haya pasado en la posteridad como con la revolución que planteó Copernico en el sistema solar, sacando a la tierra del centro del universo, o la evolución de Darwin que igualaba al humano con cualquier otra especie.

**La IA puede ser utilizada para fines no deseados**. El avance en las ramas de cualquier ciencia puede llevar a un uso inadecuado o puede resaltar las diferencias entre las personas con mayor poder adquisitivo o incluso amenazar a la vida humana en si. Los sistemas de IA autónomos por ejemplo son utilizados en las guerras para el despliegue de drones autónomos los cuales, claramente, representan una gran ventaja en la guerra. Esto puede ocasionar que se inicien muchas guerras evitables ya que alguno de los lados siente que tiene confianza en dicha tecnología. También puede darse el caso que dichos robots autónomos tomen decisiones que finalicen con la muerte de civiles inocentes.

Otra aplicación que se puede ocasionar con el uso inadecuado de IA es la de vigilar a la población civil, provocando que la vida privada de los mismos sea minima o hasta nula.

**El uso de IA puede provocar una perdida de responsabilidad**. Con el uso de las IAs entra en juego también la parte legal. Cuando se pide la opinion de un físico o un medico experto, este tiene que responder por sus acciones en caso de hacer un mal diagnostico. En el caso de que estos diagnósticos sean efectuados por una IA, ¿de quien es la culpa del diagnostico? Actualmente la corte toma a los sistemas como meras referencias y es el medico o físico el responsable por entender las recomendaciones. El dia de mañana si estos sistemas se vuelven mas confiables que los doctores, podría darse el caso de que un doctor pueda ser responsable por no haver uso de las recomendaciones de una IA.

**El uso de IA puede significar el fin de la raza humana**. Se han grabado muchas películas representando el riesgo de las maquinas, tales como Terminator, Robocop o Matrix. Los 3 principales focos de riesgo que pueden amenazar a la humanidad son: 
Un estado de estimación de una IA este mal, provocando un mal funcionamiento, afectando a cosas como que un auto calcule mal las distancias, o peor aun, un misil de un sistema de defensa detecte un ataque y genere un contraataque.
Se podría generar una IA de minimización del sufrimiento humano, como el sufrimiento es algo muy complejo de minimizar la IA podría decidir que la única forma de minimizar el sufrimiento es acabar con todos los humanos, sin humanos no habría sufrimiento. Aunque también se piensa que una maquina lo suficientemente inteligente para lograr eso, también seria capaz de entender que ese no seria el objetivo deseado.
Un sistema de IA puede evolucionar con un comportamiento no intencionado. Este es el escenario mas serio que puede desembocar en distintos caminos.
Se podría crear una maquina super inteligente, mas que cualquier hombre, alcanzando la **singularidad tecnológica**. si esto ocurre entonces la era de la humanidad habrá terminado. Otro camino posible en el futuro es la del **transhumanismo** en el cual la gente comienza a mezclarse o incluso remplazar partes de su cuerpo por invenciones robóticas o biotecnologícas. De esta manera la singularidad haría trascender a los humanos mas allá de sus limitaciones biológicas.

La posible generación de maquinas ultra inteligentes nos obliga a diseñarlas de manera cuidadosa para tratarnos correctamente. El escritor Isaac Asimov introdujo las 3 leyes de la robótica:
1) Un robot no puede herir a un humano o, por inanición, dejar que un humano sea herido.
2) Un robot debe obedecer las ordenes de un humano, excepto que estas ordenes se contradigan con la primera ley.
3) Un robot debe proteger su propia existencia siempre y cuando no entre en conflicto con las 2 leyes anteriores.
   
Estas reglas pueden llevar a casos en los que los robots se encuentren atascados entre algunas de estas reglas, debido a su definición circular.
Yudkowsky planteó el como diseñar una IA amistosa. Esta debe ser diseñada desde un comienzo, pero esta debe estar preparada para cambiar y evolucionar. Le problema radica en como preparar un sistema para evolucionar. Esto se debe ya que por ejemplo un robot de 1800 pelearía por mantener la esclavitud y eliminar el voto femenino. También se plantea que todo tipo de IA con la capacidad de aprender deberían tener sistemas de protección para evitar que esta escale mas allá de sus limites.

b)
![Alt text](<IA Fundamentos Filosóficos.png>)

c)
En mi opinion, las IAs no dejan de ser herramientas capaces de copiar el comportamiento humano, pero herramientas al fin. El planteo de si estas poseen una consciencia propia es bastante debatible porque a mi parecer podría llevar a muchas contradicciones como el hecho de poder simular todo tipo de vida de manera perfecta a traves de recuerdos artificiales. Esto ultimo a mi parecer no es posible ya que para simular con perfecta exactitud  a la vida real, seria necesario simular el 100% del universo con todas sus interacciones, una cantidad de memoria que rosa lo absurdo.

Sin embargo, si estoy de acuerdo en que la IA puede desencadenar muchos cambios en la sociedad en la que vivimos, semejantes a los que fue la revolución industrial allá por el siglo XVIII. También puede producir muchos cambios culturales y de paradigmas en la sociedad. Por ejemplo, si la IA fuera capaz de replazarnos en la mayoría de trabajos existentes, garantizándonos los productos básicos del dia, tal vez existe la posibilidad de que haya personas que no requieran de ejercer un trabajo estricto o poder trabajar mucho menos. Este para mi podría ser el escenario mas realista que podría ocurrir y que conllevaría varias dificultades ya que todas nuestras sociedades y culturas giran entorno al trabajo de las personas.

2- 
Si bien es verdad que actualmente las IAs generativas de texto pueden llegar a verse como simples "loros estocásticos", como los retratan en el articulo, creo que es intentar simplificar procesos bastante complejos que, a su manera, pueden ser similares a los que produce un cerebro humano. Además el hecho de que sean palabras colocadas estadísticamente por un modelo probabilísticos no quita la gran utilidad que puede significar para una gran cantidad de trabajos hechos por humanos, potenciando y mejorando los resultados de una manera mucho mas rápida.

A la hora de analizar el ejemplo del pulpo se destaca que el mismo no posee conocimiento del mundo real, por lo tanto no es capaz de brindar ayuda cuando se le presenta una situación que involucra una relación entre objetos de la vida cotidiana. El punto a destacar es que si bien todas las palabras son representaciones abstractas del mundo en que vivimos, no dejan de ser justamente eso, representaciones abstractas. Esto implica que pueden existir distintas representaciones de la misma cosa u objeto o incluso existir representaciones abstractas de ellas mismas y no por ello perder no ser capaz de comprenderlo. Es posible que las maquinas logren en algún punto comprender las características y relaciones de dichos objetos. 

Finalmente agregaría que creo que la IA no es una herramienta perfecta y que por lo tanto va a tener sus errores que irán mejorando a lo largo del tiempo, pero sería injusto desmerecer a la IA siendo que los humanos somos seres imperfectos con muchos errores y seguramente todo lo que seamos capaces de crear también lo será. 